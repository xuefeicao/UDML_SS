## SLURM PROLOG ###############################################################
##    Job ID : 11325074
##  Job Name : run_train_test.sh
##  Nodelist : gpu2007
##      CPUs : 
##  Mem/Node : 65536 MB
## Directory : /gpfs_home/xcao1/UDML-SS/scripts
##   Started : Fri Mar 27 17:46:52 EDT 2020
###############################################################################
module: loading 'gcc/7.2'
module: gcc: "Note: loading the gcc module overrides the gcc version on the system.  If you want to revert to the version of gcc provided by the OS, unload the gcc module."
module: loading 'anaconda/3-5.2.0'
module: loading 'cuda/10.0.130'
module: loading 'cudnn/7.4'
module: cudnn: To use: module load cuda/10.0.130
Begin Training!
25396838400
Namespace(alpha=40, batch_size=80, beta=2.0, corruption=0, data='cub', data_root='/gpfs/data/xl6/xuefei/ML/data', dim=512, epochs=600, freeze_BN=True, gallery_eq_query=True, init='random', k=16, loss='Weight', loss_base=0.75, lr=1e-05, margin=0.5, momentum=0.9, nThreads=16, net='Inception', num_clusters=100, num_instances=5, origin_width=256, orth_reg=0, pool_feature=False, pretrained=True, print_freq=20, ratio=0.16, resume='yes', rot_batch=16, rot_bt=1, rot_lr=5e-06, rot_only=0.0, save_dir='/gpfs/data/xl6/xuefei/ML/results/Deep_Metric/ckpt/Weight/cub/Inception-DIM-512-lr-0.00001-ratio-0.16-BatchSize-80-rot_lr-0.000005-self_supervision_rot-0.1-rot_bt-1-rot_batch-16-up_step-5-num_clusters-100-ALPHA-40-BETA-2', save_step=50, self_supervision_rot=0.1, up_step=5, use_test=0.0, weight_decay=0.0005, width=227)
Learn Rate  	1.0e-05
Epochs  	00600
Log Path 	/gpfs/data/xl6/xuefei/ML/results/Deep_Metric/ckpt/Weight/cub/Inception-DIM-512-lr-0.00001-ratio-0.16-BatchSize-80-rot_lr-0.000005-self_supervision_rot-0.1-rot_bt-1-rot_batch-16-up_step-5-num_clusters-100-ALPHA-40-BETA-2
Network 	 Inception
Data Set 	 cub
Batch Size  	 80
Num-Instance  	 5
Embedded Dimension 	 512
Loss Function 	Weight
Alpha 	 40
Begin to fine tune Inception Network
########################################
Sequential(
  (0): Linear(in_features=1024, out_features=512, bias=True)
  (1): ReLU(inplace=True)
  (2): Linear(in_features=512, out_features=4, bias=True)
  (3): ReLU(inplace=True)
)
loaded++++++++++++++++++++++++++++++++++
dict_keys(['inception_3a.3x3_reduce.bias', 'inception_4e.1x1.bias', 'inception_4b.1x1.bias', 'inception_4a.pool_proj.weight', 'inception_4d.1x1.weight', 'inception_3b.pool_proj.bias', 'inception_4e.1x1.weight', 'inception_4d.5x5_reduce.weight', 'inception_4b.pool_proj.weight', 'inception_3a.3x3.bias', 'inception_4b.3x3.bias', 'inception_3b.5x5_reduce.weight', 'inception_4a.1x1.bias', 'inception_3b.1x1.weight', 'inception_5b.5x5_reduce.weight', 'inception_4e.5x5.bias', 'inception_4d.1x1.bias', 'inception_4d.5x5.bias', 'inception_3b.3x3_reduce.weight', 'inception_5b.3x3.bias', 'inception_3a.pool_proj.weight', 'inception_4c.5x5_reduce.bias', 'inception_3b.3x3.bias', 'inception_5a.3x3_reduce.weight', 'inception_4e.pool_proj.weight', 'inception_4a.1x1.weight', 'inception_4e.3x3.weight', 'inception_5b.3x3_reduce.bias', 'inception_4a.5x5_reduce.weight', 'inception_4a.5x5_reduce.bias', 'inception_5a.3x3.weight', 'inception_4c.3x3.weight', 'inception_4e.5x5_reduce.bias', 'inception_4c.5x5.weight', 'inception_4a.3x3.bias', 'inception_4c.pool_proj.bias', 'inception_4d.3x3.bias', 'conv1.7x7_s2.bias', 'inception_4b.1x1.weight', 'inception_4a.pool_proj.bias', 'inception_4b.3x3_reduce.weight', 'inception_5b.5x5.bias', 'inception_3a.5x5_reduce.bias', 'inception_5a.1x1.bias', 'inception_4d.pool_proj.bias', 'conv2.3x3_reduce.bias', 'inception_4a.3x3.weight', 'inception_4d.3x3_reduce.weight', 'inception_5a.5x5_reduce.weight', 'inception_3b.5x5_reduce.bias', 'inception_4b.3x3_reduce.bias', 'inception_3a.3x3.weight', 'inception_4c.3x3_reduce.bias', 'inception_5a.3x3.bias', 'inception_4d.3x3.weight', 'inception_5b.1x1.bias', 'inception_4a.5x5.weight', 'inception_3b.3x3_reduce.bias', 'inception_4a.3x3_reduce.weight', 'inception_3a.1x1.weight', 'inception_5a.5x5_reduce.bias', 'inception_4d.pool_proj.weight', 'inception_3b.1x1.bias', 'inception_4b.5x5_reduce.weight', 'inception_3b.3x3.weight', 'inception_4c.3x3_reduce.weight', 'inception_5b.1x1.weight', 'inception_5b.5x5_reduce.bias', 'inception_4c.5x5_reduce.weight', 'inception_5b.5x5.weight', 'inception_5a.5x5.bias', 'conv1.7x7_s2.weight', 'inception_3b.5x5.weight', 'inception_3a.1x1.bias', 'inception_4c.pool_proj.weight', 'inception_4e.3x3_reduce.weight', 'inception_5a.1x1.weight', 'inception_4c.1x1.weight', 'inception_5b.pool_proj.bias', 'inception_4e.5x5.weight', 'inception_4d.5x5_reduce.bias', 'inception_4b.5x5_reduce.bias', 'inception_4e.3x3.bias', 'inception_5a.pool_proj.bias', 'inception_3b.5x5.bias', 'inception_4b.5x5.bias', 'inception_4e.3x3_reduce.bias', 'inception_4e.pool_proj.bias', 'inception_5b.3x3.weight', 'conv2.3x3.bias', 'inception_5b.3x3_reduce.weight', 'inception_3a.5x5.bias', 'inception_5a.3x3_reduce.bias', 'inception_3a.pool_proj.bias', 'inception_5a.5x5.weight', 'inception_4d.3x3_reduce.bias', 'inception_4c.5x5.bias', 'inception_4b.pool_proj.bias', 'inception_4b.3x3.weight', 'inception_3a.3x3_reduce.weight', 'inception_4c.3x3.bias', 'conv2.3x3_reduce.weight', 'inception_4e.5x5_reduce.weight', 'inception_5b.pool_proj.weight', 'inception_3a.5x5_reduce.weight', 'inception_4c.1x1.bias', 'inception_3b.pool_proj.weight', 'inception_4a.3x3_reduce.bias', 'inception_5a.pool_proj.weight', 'inception_4b.5x5.weight', 'inception_3a.5x5.weight', 'conv2.3x3.weight', 'inception_4a.5x5.bias', 'inception_4d.5x5.weight'])
114
finished
width: 	 227
bgr init
train.txt is used!
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4b4da7d68>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4b4da7d68>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    CenterCrop(size=(227, 227))
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
/users/xcao1/anaconda/my_env_1.2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Extract Features: [59/59]	Time 0.021 (0.021)	Data 51.338 (51.338)	
torch.Size([5864, 1024]) <class 'torch.Tensor'>
finish cluster
label 0 100
0.1612291255850956 (100, 1024)
width: 	 227
bgr init
train.txt is used!
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4ade76208>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4ade76208>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    CenterCrop(size=(227, 227))
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
Extract Features: [60/60]	Time 0.019 (0.019)	Data 57.927 (57.927)	
feature normalized
tensor(92839.5469) test
100 num_clusters
K-means done
[0.47045915 0.59908845 0.72451047 0.82714382 0.90074274 0.95087779] 0.5532238052960019
Epoch-0 0.4705  0.5991  0.7245  0.8271  0.9007  0.9509  0.5532
######################################## 
 BatchNorm frozen
{140688983087072, 140688983087144, 140688983087216, 140688983087288}
initial model is save at /gpfs/data/xl6/xuefei/ML/results/Deep_Metric/ckpt/Weight/cub/Inception-DIM-512-lr-0.00001-ratio-0.16-BatchSize-80-rot_lr-0.000005-self_supervision_rot-0.1-rot_bt-1-rot_batch-16-up_step-5-num_clusters-100-ALPHA-40-BETA-2
width: 	 227
bgr init
train_1.txt is used!
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4ae1d19b0>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4ae1d19b0>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    CenterCrop(size=(227, 227))
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
Epoch: [001][6/6]	Time 2.998	Loss 1.0537 	Loss_rot 1.4082 	Loss_rot_test 0.0000 	accuracy 0.0062 	Pos 0.5206	Neg 0.4138 	
Epoch: [002][6/6]	Time 2.249	Loss 1.0451 	Loss_rot 1.3667 	Loss_rot_test 0.0000 	accuracy 0.0083 	Pos 0.5149	Neg 0.3959 	
Epoch: [003][6/6]	Time 1.801	Loss 1.0489 	Loss_rot 1.4063 	Loss_rot_test 0.0000 	accuracy 0.0000 	Pos 0.5756	Neg 0.3804 	
Epoch: [004][6/6]	Time 1.879	Loss 1.0400 	Loss_rot 1.3939 	Loss_rot_test 0.0000 	accuracy 0.0021 	Pos 0.5804	Neg 0.3665 	
Epoch: [005][6/6]	Time 2.046	Loss 1.0307 	Loss_rot 1.3664 	Loss_rot_test 0.0000 	accuracy 0.0000 	Pos 0.5591	Neg 0.3757 	
width: 	 227
bgr init
train.txt is used!
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4b601a198>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
transform used: Compose(
    <data.transforms.CovertBGR object at 0x7ff4b601a198>
    Resize(size=256, interpolation=PIL.Image.BILINEAR)
    CenterCrop(size=(227, 227))
    ToTensor()
    Normalize(mean=[0.40784313725490196, 0.4588235294117647, 0.5019607843137255], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])
)
